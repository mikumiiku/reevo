# 序章：遗传算法 (Genetic Algorithm, GA) 速写

1. **灵感来源**：GA 模拟自然选择过程，把候选解视作“个体”，通过繁衍迭代提升适应度。它由三个核心支柱构成：保留优秀个体的选择、重组优秀基因的交叉、引入新基因的变异。
2. **编码与初始种群**：每个个体都用某种“染色体”表达（可是二进制串、实数向量或程序文本）。初始种群通常随机生成，也可以注入先验解以提高起点质量。
3. **适应度评估**：目标函数负责衡量每个个体的好坏。GA 并不直接求梯度，而是依赖打分结果驱动后续操作，这让它适用于非凸、不可导甚至黑盒问题。
4. **选择策略**：常见方法包括轮盘赌、锦标赛、排序选择等。本项目更像“保留前若干名”，即用精英保留 + 随机补位的方式让强者更有机会繁殖。
5. **交叉与变异**：交叉用于合并两个父母的优点（例如把不同子串拼接成新串）；变异随机翻转部分位或改写参数，以避免早熟收敛。两者协同保证全局探索能力。
6. **终止条件**：达到预设迭代次数、适应度不再提升、或评估预算耗尽时停止，并输出当前最优个体。

这个经典流程也是 ReEvo 的灵感来源：只是把传统“染色体”替换成 LLM 生成的可执行启发式代码，让遗传机制驱动大模型进行创造性迭代。

# 何谓“启发式”？

1. **概念**：启发式 (heuristic) 是面向复杂搜索或优化问题的经验性规则，强调“快速找到足够好”的解，而非穷举最优。它通常基于局部信息或经验法则，为算法提供指引。
2. **典型例子**：在旅行商问题中，“最近邻”策略就是启发式——每一步选择距离最近、尚未访问的城市，虽然不保证绝对最短，但能高效给出合理路线。
3. **在 ReEvo 中的体现**：系统要求 LLM 输出一个 `heuristics` 函数，用距离矩阵生成同维度的“偏好矩阵”。这一矩阵会被蚁群算法与信息素一起用来计算转移概率，相当于告诉蚂蚁哪些边更值得尝试。
4. **为何重要**：不同启发式对应不同的探索偏好（侧重局部 vs. 全局、静态 vs. 动态）。ReEvo 的目标就是自动发掘、组合、改进这些偏好，让求解器在给定时间预算内更稳定地找到高质量解。

# Presentation: ReEvo 与 TSP-ACO 应用综述

## 一、ReEvo 简介

### 1.1 为什么需要 ReEvo？
- **传统启发式的痛点**：依赖专家经验、调参耗时、跨问题迁移差。
- **大语言模型的机会**：具备编码与解释能力，只需自然语言提示即可产出完整算法草案。
- **ReEvo 的定位**：将 LLM 当作“语言型超启发式”，自动提出并改进求解策略，同时保持人类可阅读、可审计的实现。

### 1.1.1 ReEvo 的数学表述
- **超启发式视角**：ReEvo 在开放的启发式空间 $H$ 中搜索候选 $h$，以最小化元目标函数 $F(h)$。可形式化为
  $$
  h^* = \operatorname*{argmin}_{h \in H} F(h),
  $$
  其中 $F(h)$ 表示在问题实例分布上评估得到的期望性能。
- **语言型超启发式**：与传统 HH 只在有限算子集合中组合不同，ReEvo 让 LLM 直接生成 $H$ 内的候选代码，因此 $H$ 由提示驱动、理论上无限大。
- **邻域与搜索景观**：在“启发式即代码”的设定下，邻域由 LLM 的输出分布定义。若当前个体为 $h_c$、提示为 $x$，则
  $$
  \mathcal{N}(h_c) = \{h \mid LLM(h \mid h_c, x) > \xi \},
  $$
  其中 $\mathcal{N}(h_c)$ 表示在该提示下、生成概率超过阈值 $\xi$ 的所有候选集合。
- **景观分析**：为了衡量搜索是否平滑，ReEvo 还计算随机游走得到的适应度自相关：
  $$
  r_i = \frac{\sum_{t=1}^{T-i} (f_t-\bar f)(f_{t+i}-\bar f)}{\sum_{t=1}^{T} (f_t-\bar f)^2},
  $$
  并据此得到相关长度 $l = -1 / \ln(|r_1|)$，其中 $f_t$ 为随机游走第 $t$ 次的适应度、$\bar f$ 为其均值、$T$ 为游走长度、$r_1$ 为一步滞后的自相关系数。较大的 $l$ 意味着景观更平滑、反思提供了更强的“语言梯度”。

### 1.2 遗传算法在 ReEvo 中如何体现？
1. **选择**：每轮评估后，会把 10 个存活候选中的前几名（通常保留 4～6 个表现稳定的解）作为“父母代”，其余个体要么被淘汰，要么只保留日志供反思。
2. **交叉**：系统把两段优秀启发式的要点写成合并提示（例如“保持局部近邻偏好 + 增加远距惩罚”），指示 LLM 产出 2～4 个全新“子代”代码，从而组合不同思路。*（提示词：对应“交叉提示”，明确列出两段父母代码的亮点，并要求 LLM 在新代码中同时保留这些元素。）*
3. **变异**：额外再请求若干（约 2 个）“高变异”个体，提示中强调尝试新特征、新归一化或随机扰动，避免种群陷入同质化。*（提示词：使用“变异提示”，刻意要求 LLM 引入不同的特征组合或随机扰动，以探索全新策略。）*
4. **适者生存**：系统持续跟踪全局最优启发式，一旦发现更优结果就更新“冠军”代码；迭代结束时，该代码被正式输出并进入验证阶段。

### 1.3 反思驱动的工作流
1. **初始化**：系统一次性让 LLM 产出 30 段初始启发式，确保种群覆盖多种策略，同时用距离倒数的种子函数作为参照。
2. **候选生成**：每一代会追加 10 个新候选（与保留下来的父母共同组成下一代的 10 个参赛席位），并在生成提示中注明需要保留或融合哪些思路。
3. **评估**：统一调用该问题的测试脚本，对每个候选进行独立求解与打分；若报错或在 20 秒内未完成，就被标记为失败且不会进入保留名单。
4. **短期反思**：针对当代的最优与最差实现写出不到 20 词的差异总结，帮助下一批候选立刻避免刚刚出现的错误。
5. **长期反思**：每隔几代把多次迭代中反复有效的经验（如“强调边的对称性”“动态调节信息素衰减”）整理成 50 词以内的建议，供后续所有提示继承。
6. **持续演化**：生成—评估—反思—交叉/变异的循环会持续到耗尽函数评估预算（常见为 100 次），此时输出的“冠军代码”会再跑一次验证集确认表现。

### 1.4 对跨方向研究生的价值
- **低耦合接口**：问题描述、提示模板、评估流程彼此独立，便于在本领域快速复用。
- **探索 + 审核双轨**：LLM 负责大规模探索，研究者保留最终审稿权，确保可解释与可信。
- **成果形式友好**：产出的是完整自然语言+源码描述，便于课堂展示、论文复现或进一步工程化。

### 1.5 关键提示词（Prompt）生态
- **系统级角色设定**：首先向 LLM 声明其“优化启发式专家”身份，并要求以纯 Python 代码回应，使其始终围绕可执行实现展开。
- **问题定制用户提示**：在系统提示之上，补充旅行商问题的自然语言描述、`heuristics` 函数职责说明以及输入输出接口，确保模型理解要生成的具体函数。
- **种子启发式**：提供一个以“距离倒数”构造的基础示例，让模型从一开始就具备可运行的先验，并为交叉、变异提供参照。
- **短期反思提示**：当出现两个版本的代码时，提示模型用不到 20 个词概括“为什么后者更好”，这相当于微型交叉操作的语义化指令。
- **长期反思提示**：在多轮迭代后，会将历史经验与新增洞察合并，要求模型用不到 50 个词给出建设性建议，为后续所有候选提供共享记忆。

## 二、ReEvo 在蚁群算法求解 TSP 的案例

### 2.1 场景设定与结果
- **问题**：在 20、50、100 个城市的旅行商问题上寻找最短巡回。

- **评价方式**：对多组随机实例求平均路线长度。

- **阶段性表现**：
  | 阶段 | 数据规模 | 平均巡回长度 | 备注 |
  | --- | --- | --- | --- |
  | 种子启发式 | 50 节点训练集（5 个实例） | 6.66 | 对应 `seed_func` 的基准能力 |
  | 第一轮候选 | 50 节点训练集（前 3 个实例） | 6.35（仅 3 个实例） | 运行更快但代码存在 bug，后 2 个实例未完成 |
  | 最佳启发式 | 20 / 50 / 100 节点验证集 | 3.87 / 6.20 / 9.46 | 迭代收敛后的最终冠军代码 |

### 2.2 蚁群算法
1. **路径构造**：每只蚂蚁在构造巡回时，若当前位于城市 $i$，选择下一城市 $j$ 的概率为
   $$
   P_{i,j} = \frac{\left(\tau_{i,j}\right)^{\alpha} \left(\eta_{i,j}\right)^{\beta}}{\sum_{k \in \mathcal{N}_i} \left(\tau_{i,k}\right)^{\alpha} \left(\eta_{i,k}\right)^{\beta}},
   $$
   其中 $\tau_{i,j}$ 代表信息素强度，$\eta_{i,j}$ 为启发式信息（例如距离的倒数），$\alpha$ 与 $\beta$ 控制两者权重，$\mathcal{N}_i$ 是尚未访问的候选集合。
2. **信息素更新**：完成一轮构造后，所有边的信息素先整体衰减再叠加优秀路径带来的增量：
   $$
   \tau_{i,j} \leftarrow (1-\rho) \cdot \tau_{i,j} + \sum_{m \in \text{ants}} \Delta \tau^{(m)}_{i,j}, \quad \Delta \tau^{(m)}_{i,j} = 
   \begin{cases}
   Q / L^{(m)}, & \text{若蚂蚁 } m \text{ 经过边 } (i,j) \\
   0, & \text{否则}
   \end{cases}
   $$
   其中 $\rho$ 为蒸发系数，$Q$ 为常数，$L^{(m)}$ 是蚂蚁 $m$ 的巡回长度。更短的路径会带来更大增益。
3. **收敛机制**：多轮迭代后，信息素在优质路径上形成“正反馈”，逐步收敛到短巡回。

### 2.3 ReEvo 如何给 ACO 注入启发式
| 流程阶段 | 说明 |
| --- | --- |
| 数据准备 | 系统自动读取多组节点坐标，计算欧氏距离矩阵，并进行常规数值处理以避免自环。 |
| 启发式设计 | LLM 生成的函数会返回一张与距离矩阵配对的“偏好矩阵”，它可编码局部邻域、边权归一化、城市分层等多种信息。 |
| 遗传操作 | 交叉提示会把不同候选中的亮点策略组合，例如“保持对短边的偏好 + 加入动态衰减”；变异提示则引导生成全新想法，如结合中心性或簇结构。 |
| ACO 运行 | 固定蚂蚁数量与迭代次数（如 30 只蚂蚁 × 100 轮），利用启发式矩阵与信息素共同计算转移概率，并记录最短路线。 |
| 评估与反馈 | 对训练集的五个实例求平均作为得分，再将运行日志与失败原因转写成短期、长期反思，为下一轮提示提供素材。 |

### 2.4 实践洞察
- **反思的价值**：短期反思重点记录“为什么超时/陷入局部最优”，长期反思汇总“哪些特征或参数组合有效”，二者共同塑造下一轮交叉、变异的方向。
- **可解释的创新**：由于输出是自然语言描述 + 可读代码，研究者能够直观理解 LLM 在探索哪些策略（例如“对远距边施加更高惩罚”“优先走稠密簇”）。

### 2.5 给读者的启示
1. **跨领域复用**：只要能提供问题描述与自动评估流程，就能把 ReEvo 嵌入到其他组合优化或调度任务中。
2. **人机协作**：让 LLM 负责“提出候选 + 自检”，研究者聚焦于设定目标、审核结果与引导高层策略。
3. **朝向平台化**：通过自然语言接口与可解释输出，ReEvo 适合在教学演示、科研竞赛或工业基准中快速对比不同启发式思路。

## 三、家族选择与复活机制：ReEvo 的核心改进

### 3.1 传统遗传算法的局限性
传统 GA 的选择策略存在两个根本问题：
1. **短视贪婪**：只依据当前适应度选择，忽略个体长期演化潜力
2. **过早收敛**：优秀个体垄断繁殖机会，导致种群多样性丧失

这些问题在启发式空间搜索中尤为突出，因为一个看似平庸的启发式可能孕育出突破性的后代。

### 3.2 家族潜力

由于第一轮决定的大方向可能很有价值，我们引入 **家族潜力(FP)** 概念。评估一个个体的价值，不仅看其当前表现，更看其整个家族（family）的未来潜力。

**核心思想**：
个体的真正价值体现在其能否产生优秀的后代。一个当前表现平平但能孕育出突破性后代的个体，比一个当前优秀但无法进化的个体更有价值。

**实用化家族潜力评估**：
为了平衡计算效率和效果，我们采用加权平均近似：
$$\text{FP}(a) = \alpha \cdot \min_{a' \in C(a)} \text{obj}(a') + \beta \cdot \text{avg}_{a' \in C(a)} \text{obj}(a') - \gamma \cdot \text{std}_{a' \in C(a)} \text{obj}(a')$$

其中：
- $\alpha$：最优后代权重（默认 0.5）
- $\beta$：平均表现权重（默认 0.3）  
- $\gamma$：多样性奖励权重（默认 0.2）

### 3.3 家族追踪系统

#### 3.3.1 数据结构
每个个体扩展为：
```python
individual = {
    # 原有字段
    'code': str, 'obj': float, 'exec_success': bool,
    
    # 家族字段
    'id': str,                    # 唯一标识符
    'parent_ids': List[str],      # 父代ID列表
    'generation': int,            # 代数
    'Family_id': str,            # 家族根ID
    'birth_iteration': int,       # 出生迭代
    
    # 家族统计（动态更新）
    'family_best_obj': float,      # 家族最优目标值
    'family_avg_obj': float,       # 家族平均目标值
    'family_size': int,            # 家族大小
    'family_diversity': float,     # 家族多样性度量
}
```

#### 3.3.2 家族系统计更新
对每个家族 $L$，定期计算：
$$\text{best}_L = \min_{a \in L} \text{obj}(a)$$
$$\text{avg}_L = \frac{1}{|L|} \sum_{a \in L} \text{obj}(a)$$
$$\text{div}_L = \frac{\text{std}_{a \in L} \text{obj}(a)}{\text{mean}_{a \in L} \text{obj}(a) + \epsilon}$$

### 3.4 三层选择策略

#### 3.4.1 选择公式
给定种群 $P$，目标选择大小 $S$：
$$S_{\text{elite}} = \lfloor S \cdot r_{\text{elite}} \rfloor$$
$$S_{\text{Family}} = \lfloor S \cdot r_{\text{Family}} \rfloor$$
$$S_{\text{revival}} = S - S_{\text{elite}} - S_{\text{Family}}$$

其中 $r_{\text{elite}} + r_{\text{Family}} + r_{\text{revival}} = 1$，默认比例为 0.5 : 0.3 : 0.2。

#### 3.4.2 精英选择 (Elite Selection)
直接选择当前最优个体：
$$P_{\text{elite}} = \text{sort}(P, \text{obj})[:S_{\text{elite}}]$$

#### 3.4.3 家族选择 (Family Selection)
基于家族潜力分数选择：
$$P_{\text{Family}} = \text{sort}(P, \text{FA})[:S_{\text{Family}}]$$

#### 3.4.4 复活选择 (Revival Selection)
从未选中个体中选择多样性高的：
$$P_{\text{unselected}} = P \setminus (P_{\text{elite}} \cup P_{\text{Family}})$$
$$\text{score}_{\text{revival}}(a) = \text{FA}(a) + \lambda \cdot \text{div}_a$$
$$P_{\text{revival}} = \text{sort}(P_{\text{unselected}}, \text{score}_{\text{revival}})[:S_{\text{revival}}]$$

最终选择池：
$$P_{\text{selected}} = P_{\text{elite}} \cup P_{\text{Family}} \cup P_{\text{revival}}$$

### 3.5 复活变异机制

#### 3.5.1 动机
传统 GA 中，未被选中的个体直接被丢弃，这浪费了潜在的基因。复活机制给这些个体第二次机会。

#### 3.5.2 家族上下文引导
对复活候选 $a$，生成家族上下文：
```
Family Information:
- Best Ancestor Score: best_L
- Average Family Score: avg_L  
- Family Diversity: div_L
- Current Individual Score: obj(a)

Task: Generate BOLD mutation considering Family strengths and avoiding historical weaknesses.
```

#### 3.5.3 大胆变异策略
不同于传统的小幅变异，复活变异鼓励：
1. **大幅重构**：改变核心算法思路
2. **特征融合**：结合不同家族的优势
3. **探索创新**：尝试全新的启发式特征

### 3.6 完整演化流程

#### 3.6.1 算法伪代码
```
Initialize FamilyTracker
Register seed and initial population (each as independent Family)

while function_evals < max_fe:
    # 1. 家族统计更新
    for individual in population:
        Family_tracker.update_family_stats(individual.id)
    
    # 2. 三层选择
    selected = Family_aware_select(population)
    
    # 3. 短期反思
    reflection_tuple = short_term_reflection(selected)
    
    # 4. 交叉操作
    offspring = crossover(reflection_tuple)
    register_offspring(offspring, parents=selected)
    
    # 5. 变异操作
    mutants = mutate()
    register_offspring(mutants, parents=[elitist])
    
    # 6. 复活变异
    revival_candidates = population \ selected
    revival_offspring = revival_mutate(revival_candidates)
    register_offspring(revival_offspring, parents=revival_candidates)
    
    # 7. 长期反思
    long_term_reflection(reflection_tuple[0])
    
    # 8. 种群更新
    population = evaluate(offspring + mutants + revival_offspring)

return best_individual_overall
```

#### 3.6.2 关键创新点
1. **家族感知**：选择考虑长期潜力而非短期表现
2. **多样性维护**：三层选择确保探索与利用平衡
3. **第二次机会**：复活机制避免基因浪费
4. **上下文引导**：LLM 变异时利用家族历史信息

### 3.7 实验验证

#### 3.7.3 性能对比
| 方法 | TSP-20 | TSP-50 | TSP-100 |
|------|--------|--------|---------|
| 传统GA | 3.87 | 6.20 | 9.46 |
| 家族复活GA | 3.86 | 5.85 | 8.39 |
| GA种子 | - | 6.61 | - |

#### 3.8.3 适用场景
- ✅ 搜索空间复杂，容易陷入局部最优
- ✅ 需要保持种群多样性的演化问题  
- ✅ 启发式空间的自适应搜索
- ✅ 大模型驱动的程序合成任务
